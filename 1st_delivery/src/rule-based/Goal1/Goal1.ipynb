{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information extracted from the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These suffixes were taken from the train dataset\n",
    "DRUG_SUFFIXES = [\"oin\", \"ine\",\"ide\", \"cin\", \"fil\", \"ion\", \"mil\", \"tal\", \"rin\", \"lin\", \"ium\", \"ril\", \"nol\",\"lyn\",\n",
    "\t\t\t\t\"hol\", \"ole\",\"mic\",\"xic\",\"xib\",\"vir\",\"mab\",\"vec\",\"ast\",\"lax\",\"sin\",\"pam\",\"tan\"]\n",
    "\n",
    "\n",
    "DRUG_COMPOSED_WORDS = ['acid','sodium','alkaloids','hydrochloride','f2alpha','edisylate','iodide','sulfate','acetate'\n",
    "\t\t\t\t\t\t'antiinflammatory','mustard','hcl','mofetil','gallate','cations','nitrate']\n",
    "\n",
    "GROUP_COMPOSED_LAST_WORDS = [\n",
    "\t'adjuvant',\n",
    "\t'agonist',\n",
    "\t'alkaloid',\n",
    "\t'antibiotic',\n",
    "\t'antidepressent',\n",
    "\t'anti-inflammatory',\n",
    "\t'blocker',\n",
    "\t'class',\n",
    "\t'compound',\n",
    "\t'depressants',\n",
    "\t'diuretic',\n",
    "\t'drug',\n",
    "\t'hormone',\n",
    "\t'inhibitor',\n",
    "\t'medication',\n",
    "\t'product',\n",
    "\t'solution',\n",
    "\t'steroid',\n",
    "\t'vaccine',\n",
    "\t'vasodilator'\n",
    "]\n",
    "\n",
    "GROUP_COMPOSED_MIDDLE_WORDS = [\n",
    "\t'oxidase',\n",
    "\t'channel',\n",
    "\t'anti-inflammatory',\n",
    "\t'blocking',\n",
    "\t'reuptake',\n",
    "\t'serotonin',\n",
    "\t'reductase',\n",
    "\t'pump',\n",
    "\t'depressant',\n",
    "\t'anhydrase'\n",
    "]\n",
    "ALL_COMPOSED_WORDS = DRUG_COMPOSED_WORDS + GROUP_COMPOSED_LAST_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions from the extract entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_token(ret, name, offset1, offset2, classtype):\n",
    "\tret.append(dict(name=name, offset=str(offset1) + '-' + str(offset2), type=classtype))\n",
    "\treturn ret\n",
    "\n",
    "\n",
    "def match_words(list_words_1, list_words_2):\n",
    "\tfor i in range(min(len(list_words_1), len(list_words_2))):\n",
    "\t\tif list_words_1[i][0] != list_words_2[i]:\n",
    "\t\t\treturn False\n",
    "\treturn True\n",
    "\n",
    "\n",
    "def match_suffix(token, suffixes):\n",
    "\tfor suf in suffixes:\n",
    "\t\tif re.search(\".+\" + suf + \"$\", token):\n",
    "\t\t\treturn True\n",
    "\treturn False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract entities function\n",
    "\n",
    "- if a word shows in the trainning data we detect them with the same class\n",
    "- if a tokken matches any of the affixes previously declared (drug composed words taking into consideration as well)\n",
    "- We saw that several vitamines are usually as type drugs and some others as type group\n",
    "- We detect composed words from type groups (which usually is the one with more composed words)\n",
    "- Capital letters most probably are brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(token_list):\n",
    "\tret = []\n",
    "\twith open('entities/trainingFeatures/entity_dict.json', 'r') as f:\n",
    "\t\ttraining_words_dict = json.load(f)\n",
    "\tskipwords = 0\n",
    "\tfor i,token in enumerate(token_list):\n",
    "\t\tappended = False\n",
    "\t\tif skipwords != 0:\n",
    "\t\t\tskipwords -= 1\n",
    "\t\t\tappended = True\n",
    "\t\t# If token is any word that appears in the training data\n",
    "\t\tif not appended:\n",
    "\t\t\tif token[0] in training_words_dict:\n",
    "\t\t\t\twords = training_words_dict[token[0]][0]\n",
    "\t\t\t\ttag = training_words_dict[token[0]][1]\n",
    "\t\t\t\tappended = match_words(token_list[i:], words)\n",
    "\t\t\t\tif appended:\n",
    "\t\t\t\t\tskipwords = len(words)\n",
    "\t\t\t\t\tword_appended = token[0]\n",
    "\t\t\t\t\tif len(words) > 0:\n",
    "\t\t\t\t\t\tword_appended += ' ' + ' '.join(words)\n",
    "\t\t\t\t\tappend_token(ret, word_appended, token[1], token_list[i+skipwords][2], tag)\n",
    "\t\t# If the token matches any custom affix\n",
    "\t\tif not appended:\n",
    "\t\t\tif match_suffix(token[0].lower(), DRUG_SUFFIXES):\n",
    "\t\t\t\tif len(token_list) > i+1:\n",
    "\t\t\t\t\t#If the following token is in DRUG_COMPOSED_WORDS both tokens will be a drug\n",
    "\t\t\t\t\tfor words in DRUG_COMPOSED_WORDS:\n",
    "\t\t\t\t\t\tif token_list[i+1][0].lower() == words:\n",
    "\t\t\t\t\t\t\tappended = True\n",
    "\t\t\t\t\t\t\tappend_token(ret,token[0]+\" \"+token_list[i+1][0],token[1],token_list[i+1][2],\"drug\")\n",
    "\t\t\t\tif not appended:\n",
    "\t\t\t\t\tappended = True\n",
    "\t\t\t\t\tappend_token(ret,token[0],token[1],token[2],\"drug\")\n",
    "\t\t# Vitamins C, E, B*, D* are drugs\n",
    "\t\tif not appended and token[0].lower() == 'vitamin' and len(token_list) > i+1 and re.search(\"^(C|E|[BD][\\w-]+)$\", token_list[i+1][0]):\n",
    "\t\t\tappended = True\n",
    "\t\t\tappend_token(ret,token[0]+\" \"+token_list[i+1][0],token[1],token_list[i+1][2],\"drug\")\n",
    "\t\t# Vitamins D*, K*, A are group\n",
    "\t\tif not appended and token[0].lower() == 'vitamin' and len(token_list) > i+1:\n",
    "\t\t\tif len(token_list) > i+2 and\\\n",
    "\t\t\t\t\t(token_list[i+1][0]=='D' and (token_list[i+2][0].lower() == 'analogue' or token_list[i+2][0].lower() == 'preparations') or\\\n",
    "\t\t\t\t\t(token_list[i+1][0] == 'K' and token_list[i+2][0].lower() == 'antagonists')):\n",
    "\t\t\t\tappended = True\n",
    "\t\t\t\tappend_token(ret,token[0]+\" \"+token_list[i+1][0]+\" \"+token_list[i+2][0],token[1],token_list[i+2][2],\"group\")\n",
    "\t\t\telif token_list[i+1][0] == 'A' or token_list[i+1][0] == 'D' or token_list[i+1][0] == 'K':\n",
    "\t\t\t\tappended = True\n",
    "\t\t\t\tappend_token(ret,token[0]+\" \"+token_list[i+1][0],token[1],token_list[i+1][2],\"group\")\n",
    "\t\t#Capital letters most probably are brands\n",
    "\t\t## Extremely useful\n",
    "\t\tif not appended and token[0].isupper() and len(token[0]) > 4:\n",
    "\t\t\tappended = True\n",
    "\t\t\tappend_token(ret,token[0],token[1],token[2],\"brand\")\n",
    "\t\t#Composed words belonging to group\n",
    "\t\t## This rule creates a lot of hits and a lot of misses (not very precise)\n",
    "\t\tif not appended:\n",
    "\t\t\tfor words in GROUP_COMPOSED_LAST_WORDS:\n",
    "\t\t\t\tif i-1 >= 0 and re.search(words + \"s?$\", token[0]):\n",
    "\t\t\t\t\tstop = False\n",
    "\t\t\t\t\tj = 0\n",
    "\t\t\t\t\twhile(not stop and i-j >= 0):\n",
    "\t\t\t\t\t\tstop = True\n",
    "\t\t\t\t\t\tj += 1\n",
    "\t\t\t\t\t\tfor mid_words in GROUP_COMPOSED_MIDDLE_WORDS:\n",
    "\t\t\t\t\t\t\tif (token_list[i-j][0] == mid_words):\n",
    "\t\t\t\t\t\t\t\tstop = False\n",
    "\t\t\t\t\tappended = True\n",
    "\t\t\t\t\tappend_token(ret,token_list[i-j][0]+\" \"+token[0],token_list[i-j][1],token[2],\"group\")\n",
    "\treturn ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
